{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "load_dotenv()\n",
    "logging.langsmith(\"TeddyNote-Parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU langchain-teddynote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장할 State 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "\n",
    "# GraphState 상태를 저장하는 용도로 사용합니다.\n",
    "class GraphState(TypedDict):\n",
    "    filepath: str  # path\n",
    "    filetype: str  # pdf\n",
    "    page_numbers: list[int]  # page numbers\n",
    "    batch_size: int  # batch size\n",
    "    split_filepaths: list[str]  # split files\n",
    "    analyzed_files: list[str]  # analyzed files\n",
    "    page_elements: dict[int, dict[str, list[dict]]]  # page elements\n",
    "    page_metadata: dict[int, dict]  # page metadata\n",
    "    page_summary: dict[int, str]  # page summary\n",
    "    images: list[str]  # image paths\n",
    "    images_summary: list[str]  # image summary\n",
    "    tables: list[str]  # table\n",
    "    tables_summary: dict[int, str]  # table summary\n",
    "    texts: list[str]  # text\n",
    "    texts_summary: list[str]  # text summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문서를 배치 단위로 분할 (10 page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pymupdf\n",
    "import json\n",
    "import requests\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pdf(state: GraphState):\n",
    "    \"\"\"\n",
    "    입력 PDF를 여러 개의 작은 PDF 파일로 분할합니다.\n",
    "\n",
    "    :param state: GraphState 객체, PDF 파일 경로와 배치 크기 정보를 포함\n",
    "    :return: 분할된 PDF 파일 경로 목록을 포함한 GraphState 객체\n",
    "    \"\"\"\n",
    "    # PDF 파일 경로와 배치 크기 추출\n",
    "    filepath = state[\"filepath\"]\n",
    "    batch_size = state[\"batch_size\"]\n",
    "\n",
    "    # PDF 파일 열기\n",
    "    input_pdf = pymupdf.open(filepath)\n",
    "    num_pages = len(input_pdf)\n",
    "    print(f\"총 페이지 수: {num_pages}\")\n",
    "\n",
    "    ret = []\n",
    "    # PDF 분할 작업 시작\n",
    "    for start_page in range(0, num_pages, batch_size):\n",
    "        # 배치의 마지막 페이지 계산 (전체 페이지 수를 초과하지 않도록)\n",
    "        end_page = min(start_page + batch_size, num_pages) - 1\n",
    "\n",
    "        # 분할된 PDF 파일명 생성\n",
    "        input_file_basename = os.path.splitext(filepath)[0]\n",
    "        output_file = f\"{input_file_basename}_{start_page:04d}_{end_page:04d}.pdf\"\n",
    "        print(f\"분할 PDF 생성: {output_file}\")\n",
    "\n",
    "        # 새로운 PDF 파일 생성 및 페이지 삽입\n",
    "        with pymupdf.open() as output_pdf:\n",
    "            output_pdf.insert_pdf(input_pdf, from_page=start_page, to_page=end_page)\n",
    "            output_pdf.save(output_file)\n",
    "            ret.append(output_file)\n",
    "\n",
    "    # 원본 PDF 파일 닫기\n",
    "    input_pdf.close()\n",
    "\n",
    "    # 분할된 PDF 파일 경로 목록을 포함한 GraphState 객체 반환\n",
    "    return GraphState(split_filepaths=ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_state 가 3 split_pdf 로 update ehla\n",
    "state = GraphState(filepath=\"data/sample-report.pdf\", batch_size=10)\n",
    "state_out = split_pdf(state)\n",
    "state.update(state_out)\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layout Analyzer 를 사용하여 문서를 element 단위로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayoutAnalyzer:\n",
    "    def __init__(self, api_key):\n",
    "        \"\"\"\n",
    "        LayoutAnalyzer 클래스의 생성자\n",
    "\n",
    "        :param api_key: Upstage API 인증을 위한 API 키\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "\n",
    "    def _upstage_layout_analysis(self, input_file):\n",
    "        \"\"\"\n",
    "        Upstage의 레이아웃 분석 API를 호출하여 문서 분석을 수행합니다.\n",
    "\n",
    "        :param input_file: 분석할 PDF 파일의 경로\n",
    "        :return: 분석 결과가 저장된 JSON 파일의 경로\n",
    "        \"\"\"\n",
    "        # API 요청 헤더 설정\n",
    "        headers = {\"Authorization\": f\"Bearer {self.api_key}\"}\n",
    "\n",
    "        # API 요청 데이터 설정 (OCR 비활성화)\n",
    "        data = {\"ocr\": False}\n",
    "\n",
    "        # 분석할 PDF 파일 열기\n",
    "        files = {\"document\": open(input_file, \"rb\")}\n",
    "\n",
    "        # API 요청 보내기\n",
    "        response = requests.post(\n",
    "            \"https://api.upstage.ai/v1/document-ai/layout-analysis\",\n",
    "            headers=headers,\n",
    "            data=data,\n",
    "            files=files,\n",
    "        )\n",
    "\n",
    "        # API 응답 처리 및 결과 저장\n",
    "        if response.status_code == 200:\n",
    "            # 분석 결과를 저장할 JSON 파일 경로 생성\n",
    "            output_file = os.path.splitext(input_file)[0] + \".json\"\n",
    "\n",
    "            # 분석 결과를 JSON 파일로 저장\n",
    "            with open(output_file, \"w\") as f:\n",
    "                json.dump(response.json(), f, ensure_ascii=False)\n",
    "\n",
    "            return output_file\n",
    "        else:\n",
    "            # API 요청이 실패한 경우 예외 발생\n",
    "            raise ValueError(f\"API 요청 실패. 상태 코드: {response.status_code}\")\n",
    "\n",
    "    def execute(self, input_file):\n",
    "        \"\"\"\n",
    "        주어진 입력 파일에 대해 레이아웃 분석을 실행합니다.\n",
    "\n",
    "        :param input_file: 분석할 PDF 파일의 경로\n",
    "        :return: 분석 결과가 저장된 JSON 파일의 경로\n",
    "        \"\"\"\n",
    "        return self._upstage_layout_analysis(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_layout(state: GraphState):\n",
    "    # 분할된 PDF 파일 목록을 가져옵니다.\n",
    "    split_files = state[\"split_filepaths\"]\n",
    "\n",
    "    # LayoutAnalyzer 객체를 생성합니다. API 키는 환경 변수에서 가져옵니다.\n",
    "    analyzer = LayoutAnalyzer(os.environ.get(\"UPSTAGE_API_KEY\"))\n",
    "\n",
    "    # 분석된 파일들의 경로를 저장할 리스트를 초기화합니다.\n",
    "    analyzed_files = []\n",
    "\n",
    "    # 각 분할된 PDF 파일에 대해 레이아웃 분석을 수행합니다.\n",
    "    for file in split_files:\n",
    "        # 레이아웃 분석을 실행하고 결과 파일 경로를 리스트에 추가합니다.\n",
    "        analyzed_files.append(analyzer.execute(file))\n",
    "\n",
    "    # 분석된 파일 경로들을 정렬하여 새로운 GraphState 객체를 생성하고 반환합니다.\n",
    "    # 정렬은 파일들의 순서를 유지하기 위해 수행됩니다.\n",
    "    return GraphState(analyzed_files=sorted(analyzed_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_out = analyze_layout(state)\n",
    "state.update(state_out)\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 페이지 메타데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def extract_start_end_page(filename):\n",
    "    \"\"\"\n",
    "    파일 이름에서 시작 페이지와 끝 페이지 번호를 추출하는 함수입니다.\n",
    "\n",
    "    :param filename: 분석할 파일의 이름\n",
    "    :return: 시작 페이지 번호와 끝 페이지 번호를 튜플로 반환\n",
    "    \"\"\"\n",
    "    # 파일 경로에서 파일 이름만 추출\n",
    "    file_name = os.path.basename(filename)\n",
    "    # 파일 이름을 '_' 기준으로 분리\n",
    "    file_name_parts = file_name.split(\"_\")\n",
    "\n",
    "    if len(file_name_parts) >= 3:\n",
    "        # 파일 이름의 뒤에서 두 번째 부분에서 숫자를 추출하여 시작 페이지로 설정\n",
    "        start_page = int(re.findall(r\"(\\d+)\", file_name_parts[-2])[0])\n",
    "        # 파일 이름의 마지막 부분에서 숫자를 추출하여 끝 페이지로 설정\n",
    "        end_page = int(re.findall(r\"(\\d+)\", file_name_parts[-1])[0])\n",
    "    else:\n",
    "        # 파일 이름 형식이 예상과 다를 경우 기본값 설정\n",
    "        start_page, end_page = 0, 0\n",
    "\n",
    "    return start_page, end_page\n",
    "\n",
    "\n",
    "def extract_page_metadata(state: GraphState):\n",
    "    \"\"\"\n",
    "    분석된 JSON 파일들에서 페이지 메타데이터를 추출하는 함수입니다.\n",
    "\n",
    "    :param state: 현재의 GraphState 객체\n",
    "    :return: 페이지 메타데이터가 추가된 새로운 GraphState 객체\n",
    "    \"\"\"\n",
    "    # 분석된 JSON 파일 목록 가져오기\n",
    "    json_files = state[\"analyzed_files\"]\n",
    "\n",
    "    # 페이지 메타데이터를 저장할 딕셔너리 초기화\n",
    "    page_metadata = dict()\n",
    "\n",
    "    for json_file in json_files:\n",
    "        # JSON 파일 열기 및 데이터 로드\n",
    "        with open(json_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # 파일명에서 시작 페이지 번호 추출\n",
    "        start_page, _ = extract_start_end_page(json_file)\n",
    "\n",
    "        # JSON 데이터에서 각 페이지의 메타데이터 추출\n",
    "        for element in data[\"metadata\"][\"pages\"]:\n",
    "            # 원본 페이지 번호\n",
    "            original_page = int(element[\"page\"])\n",
    "            # 상대적 페이지 번호 계산 (전체 문서 기준)\n",
    "            relative_page = start_page + original_page - 1\n",
    "\n",
    "            # 페이지 크기 정보 추출\n",
    "            metadata = {\n",
    "                \"size\": [\n",
    "                    int(element[\"width\"]),\n",
    "                    int(element[\"height\"]),\n",
    "                ],\n",
    "            }\n",
    "            # 상대적 페이지 번호를 키로 하여 메타데이터 저장\n",
    "            page_metadata[relative_page] = metadata\n",
    "\n",
    "    # 추출된 페이지 메타데이터로 새로운 GraphState 객체 생성 및 반환\n",
    "    return GraphState(page_metadata=page_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "페이지별 사이즈를 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_out = extract_page_metadata(state)\n",
    "state.update(state_out)\n",
    "state[\"page_metadata\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 페이지별 HTML Element 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_elements(state: GraphState):\n",
    "    # 분석된 JSON 파일 목록을 가져옵니다.\n",
    "    json_files = state[\"analyzed_files\"]\n",
    "\n",
    "    # 페이지별 요소를 저장할 딕셔너리를 초기화합니다.\n",
    "    page_elements = dict()\n",
    "\n",
    "    # 전체 문서에서 고유한 요소 ID를 부여하기 위한 카운터입니다.\n",
    "    element_id = 0\n",
    "\n",
    "    # 각 JSON 파일을 순회하며 처리합니다.\n",
    "    for json_file in json_files:\n",
    "        # 파일명에서 시작 페이지 번호를 추출합니다.\n",
    "        start_page, _ = extract_start_end_page(json_file)\n",
    "\n",
    "        # JSON 파일을 열어 데이터를 로드합니다.\n",
    "        with open(json_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # JSON 데이터의 각 요소를 처리합니다.\n",
    "        for element in data[\"elements\"]:\n",
    "            # 원본 페이지 번호를 정수로 변환합니다.\n",
    "            original_page = int(element[\"page\"])\n",
    "            # 전체 문서 기준의 상대적 페이지 번호를 계산합니다.\n",
    "            relative_page = start_page + original_page - 1\n",
    "\n",
    "            # 해당 페이지의 요소 리스트가 없으면 새로 생성합니다.\n",
    "            if relative_page not in page_elements:\n",
    "                page_elements[relative_page] = []\n",
    "\n",
    "            # 요소에 고유 ID를 부여합니다.\n",
    "            element[\"id\"] = element_id\n",
    "            element_id += 1\n",
    "\n",
    "            # 요소의 페이지 번호를 상대적 페이지 번호로 업데이트합니다.\n",
    "            element[\"page\"] = relative_page\n",
    "            # 요소를 해당 페이지의 리스트에 추가합니다.\n",
    "            page_elements[relative_page].append(element)\n",
    "\n",
    "    # 추출된 페이지별 요소 정보로 새로운 GraphState 객체를 생성하여 반환합니다.\n",
    "    return GraphState(page_elements=page_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_out = extract_page_elements(state)\n",
    "state.update(state_out)\n",
    "state[\"page_elements\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추출된 페이지를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"page_elements\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 각 페이지의 태그를 분해합니다.\n",
    "\n",
    "- images, tables, text 를 분해합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tag_elements_per_page(state: GraphState):\n",
    "    # GraphState 객체에서 페이지 요소들을 가져옵니다.\n",
    "    page_elements = state[\"page_elements\"]\n",
    "\n",
    "    # 파싱된 페이지 요소들을 저장할 새로운 딕셔너리를 생성합니다.\n",
    "    parsed_page_elements = dict()\n",
    "\n",
    "    # 각 페이지와 해당 페이지의 요소들을 순회합니다.\n",
    "    for key, page_element in page_elements.items():\n",
    "        # 이미지, 테이블, 텍스트 요소들을 저장할 리스트를 초기화합니다.\n",
    "        image_elements = []\n",
    "        table_elements = []\n",
    "        text_elements = []\n",
    "\n",
    "        # 페이지의 각 요소를 순회하며 카테고리별로 분류합니다.\n",
    "        for element in page_element:\n",
    "            if element[\"category\"] == \"figure\":\n",
    "                # 이미지 요소인 경우 image_elements 리스트에 추가합니다.\n",
    "                image_elements.append(element)\n",
    "            elif element[\"category\"] == \"table\":\n",
    "                # 테이블 요소인 경우 table_elements 리스트에 추가합니다.\n",
    "                table_elements.append(element)\n",
    "            else:\n",
    "                # 그 외의 요소는 모두 텍스트 요소로 간주하여 text_elements 리스트에 추가합니다.\n",
    "                text_elements.append(element)\n",
    "\n",
    "        # 분류된 요소들을 페이지 키와 함께 새로운 딕셔너리에 저장합니다.\n",
    "        parsed_page_elements[key] = {\n",
    "            \"image_elements\": image_elements,\n",
    "            \"table_elements\": table_elements,\n",
    "            \"text_elements\": text_elements,\n",
    "            \"elements\": page_element,  # 원본 페이지 요소도 함께 저장합니다.\n",
    "        }\n",
    "\n",
    "    # 파싱된 페이지 요소들을 포함한 새로운 GraphState 객체를 반환합니다.\n",
    "    return GraphState(page_elements=parsed_page_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_out = extract_tag_elements_per_page(state)\n",
    "state.update(state_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"page_elements\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"page_elements\"][2].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"page_elements\"][2][\"image_elements\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_out[\"page_elements\"][2][\"table_elements\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"page_elements\"][2][\"text_elements\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 페이지 번호를 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_numbers(state: GraphState):\n",
    "    return GraphState(page_numbers=list(state[\"page_elements\"].keys()))\n",
    "\n",
    "\n",
    "state_out = page_numbers(state)\n",
    "state.update(state_out)\n",
    "state[\"page_numbers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지를 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageCropper:\n",
    "    @staticmethod\n",
    "    def pdf_to_image(pdf_file, page_num, dpi=300):\n",
    "        \"\"\"\n",
    "        PDF 파일의 특정 페이지를 이미지로 변환하는 메서드\n",
    "\n",
    "        :param page_num: 변환할 페이지 번호 (1부터 시작)\n",
    "        :param dpi: 이미지 해상도 (기본값: 300)\n",
    "        :return: 변환된 이미지 객체\n",
    "        \"\"\"\n",
    "        with pymupdf.open(pdf_file) as doc:\n",
    "            page = doc[page_num].get_pixmap(dpi=dpi)\n",
    "            target_page_size = [page.width, page.height]\n",
    "            page_img = Image.frombytes(\"RGB\", target_page_size, page.samples)\n",
    "        return page_img\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_coordinates(coordinates, output_page_size):\n",
    "        \"\"\"\n",
    "        좌표를 정규화하는 정적 메서드\n",
    "\n",
    "        :param coordinates: 원본 좌표 리스트\n",
    "        :param output_page_size: 출력 페이지 크기 [너비, 높이]\n",
    "        :return: 정규화된 좌표 (x1, y1, x2, y2)\n",
    "        \"\"\"\n",
    "        x_values = [coord[\"x\"] for coord in coordinates]\n",
    "        y_values = [coord[\"y\"] for coord in coordinates]\n",
    "        x1, y1, x2, y2 = min(x_values), min(y_values), max(x_values), max(y_values)\n",
    "\n",
    "        return (\n",
    "            x1 / output_page_size[0],\n",
    "            y1 / output_page_size[1],\n",
    "            x2 / output_page_size[0],\n",
    "            y2 / output_page_size[1],\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def crop_image(img, coordinates, output_file):\n",
    "        \"\"\"\n",
    "        이미지를 주어진 좌표에 따라 자르고 저장하는 정적 메서드\n",
    "\n",
    "        :param img: 원본 이미지 객체\n",
    "        :param coordinates: 정규화된 좌표 (x1, y1, x2, y2)\n",
    "        :param output_file: 저장할 파일 경로\n",
    "        \"\"\"\n",
    "        img_width, img_height = img.size\n",
    "        x1, y1, x2, y2 = [\n",
    "            int(coord * dim)\n",
    "            for coord, dim in zip(coordinates, [img_width, img_height] * 2)\n",
    "        ]\n",
    "        cropped_img = img.crop((x1, y1, x2, y2))\n",
    "        cropped_img.save(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_table = state[\"page_elements\"][2][\"table_elements\"][0]\n",
    "sample_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = state[\"page_elements\"][2][\"image_elements\"][0]\n",
    "sample_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(state: GraphState):\n",
    "    \"\"\"\n",
    "    PDF 파일에서 이미지를 추출하고 크롭하는 함수\n",
    "\n",
    "    :param state: GraphState 객체\n",
    "    :return: 크롭된 이미지 정보가 포함된 GraphState 객체\n",
    "    \"\"\"\n",
    "    pdf_file = state[\"filepath\"]  # PDF 파일 경로\n",
    "    page_numbers = state[\"page_numbers\"]  # 처리할 페이지 번호 목록\n",
    "    output_folder = os.path.splitext(pdf_file)[0]  # 출력 폴더 경로 설정\n",
    "    os.makedirs(output_folder, exist_ok=True)  # 출력 폴더 생성\n",
    "\n",
    "    cropped_images = dict()  # 크롭된 이미지 정보를 저장할 딕셔너리\n",
    "    for page_num in page_numbers:\n",
    "        pdf_image = ImageCropper.pdf_to_image(\n",
    "            pdf_file, page_num\n",
    "        )  # PDF 페이지를 이미지로 변환\n",
    "        for element in state[\"page_elements\"][page_num][\"image_elements\"]:\n",
    "            if element[\"category\"] == \"figure\":\n",
    "                # 이미지 요소의 좌표를 정규화\n",
    "                normalized_coordinates = ImageCropper.normalize_coordinates(\n",
    "                    element[\"bounding_box\"], state[\"page_metadata\"][page_num][\"size\"]\n",
    "                )\n",
    "\n",
    "                # 크롭된 이미지 저장 경로 설정\n",
    "                output_file = os.path.join(output_folder, f\"{element['id']}.png\")\n",
    "                # 이미지 크롭 및 저장\n",
    "                ImageCropper.crop_image(pdf_image, normalized_coordinates, output_file)\n",
    "                cropped_images[element[\"id\"]] = output_file\n",
    "                print(f\"page:{page_num}, id:{element['id']}, path: {output_file}\")\n",
    "    return GraphState(\n",
    "        images=cropped_images\n",
    "    )  # 크롭된 이미지 정보를 포함한 GraphState 반환\n",
    "\n",
    "\n",
    "def crop_table(state: GraphState):\n",
    "    \"\"\"\n",
    "    PDF 파일에서 표를 추출하고 크롭하는 함수\n",
    "\n",
    "    :param state: GraphState 객체\n",
    "    :return: 크롭된 표 이미지 정보가 포함된 GraphState 객체\n",
    "    \"\"\"\n",
    "    pdf_file = state[\"filepath\"]  # PDF 파일 경로\n",
    "    page_numbers = state[\"page_numbers\"]  # 처리할 페이지 번호 목록\n",
    "    output_folder = os.path.splitext(pdf_file)[0]  # 출력 폴더 경로 설정\n",
    "    os.makedirs(output_folder, exist_ok=True)  # 출력 폴더 생성\n",
    "\n",
    "    cropped_images = dict()  # 크롭된 표 이미지 정보를 저장할 딕셔너리\n",
    "    for page_num in page_numbers:\n",
    "        pdf_image = ImageCropper.pdf_to_image(\n",
    "            pdf_file, page_num\n",
    "        )  # PDF 페이지를 이미지로 변환\n",
    "        for element in state[\"page_elements\"][page_num][\"table_elements\"]:\n",
    "            if element[\"category\"] == \"table\":\n",
    "                # 표 요소의 좌표를 정규화\n",
    "                normalized_coordinates = ImageCropper.normalize_coordinates(\n",
    "                    element[\"bounding_box\"], state[\"page_metadata\"][page_num][\"size\"]\n",
    "                )\n",
    "\n",
    "                # 크롭된 표 이미지 저장 경로 설정\n",
    "                output_file = os.path.join(output_folder, f\"{element['id']}.png\")\n",
    "                # 표 이미지 크롭 및 저장\n",
    "                ImageCropper.crop_image(pdf_image, normalized_coordinates, output_file)\n",
    "                cropped_images[element[\"id\"]] = output_file\n",
    "                print(f\"page:{page_num}, id:{element['id']}, path: {output_file}\")\n",
    "    return GraphState(\n",
    "        tables=cropped_images\n",
    "    )  # 크롭된 표 이미지 정보를 포함한 GraphState 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[\"page_elements\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_out = crop_image(state)\n",
    "state.update(state_out)\n",
    "state[\"images\"]\n",
    "# state.update(state6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_out = crop_table(state)\n",
    "state.update(state_out)\n",
    "state[\"tables\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 페이지 텍스트 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_text(state: GraphState):\n",
    "    # 상태 객체에서 페이지 번호 목록을 가져옵니다.\n",
    "    page_numbers = state[\"page_numbers\"]\n",
    "\n",
    "    # 추출된 텍스트를 저장할 딕셔너리를 초기화합니다.\n",
    "    extracted_texts = dict()\n",
    "\n",
    "    # 각 페이지 번호에 대해 반복합니다.\n",
    "    for page_num in page_numbers:\n",
    "        # 현재 페이지의 텍스트를 저장할 빈 문자열을 초기화합니다.\n",
    "        extracted_texts[page_num] = \"\"\n",
    "\n",
    "        # 현재 페이지의 모든 텍스트 요소에 대해 반복합니다.\n",
    "        for element in state[\"page_elements\"][page_num][\"text_elements\"]:\n",
    "            # 각 텍스트 요소의 내용을 현재 페이지의 텍스트에 추가합니다.\n",
    "            extracted_texts[page_num] += element[\"text\"]\n",
    "\n",
    "    # 추출된 텍스트를 포함한 새로운 GraphState 객체를 반환합니다.\n",
    "    return GraphState(texts=extracted_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_out = extract_page_text(state)\n",
    "state.update(state_out)\n",
    "state[\"texts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.combine_documents import (\n",
    "    create_stuff_documents_chain,\n",
    ")\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 요약을 위한 프롬프트 템플릿을 정의합니다.\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Please summarize the sentence according to the following REQUEST.\n",
    "    \n",
    "REQUEST:\n",
    "1. Summarize the main points in bullet points.\n",
    "2. Write the summary in same language as the context.\n",
    "3. DO NOT translate any technical terms.\n",
    "4. DO NOT include any unnecessary information.\n",
    "5. Summary must include important entities, numerical values.\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "SUMMARY:\"\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# ChatOpenAI 모델의 또 다른 인스턴스를 생성합니다. (이전 인스턴스와 동일한 설정)\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# 문서 요약을 위한 체인을 생성합니다.\n",
    "# 이 체인은 여러 문서를 입력받아 하나의 요약된 텍스트로 결합합니다.\n",
    "text_summary_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_summary(state: GraphState):\n",
    "    # state에서 텍스트 데이터를 가져옵니다.\n",
    "    texts = state[\"texts\"]\n",
    "\n",
    "    # 요약된 텍스트를 저장할 딕셔너리를 초기화합니다.\n",
    "    text_summary = dict()\n",
    "\n",
    "    # texts.items()를 페이지 번호(키)를 기준으로 오름차순 정렬합니다.\n",
    "    sorted_texts = sorted(texts.items(), key=lambda x: x[0])\n",
    "\n",
    "    # 각 페이지의 텍스트를 Document 객체로 변환하여 입력 리스트를 생성합니다.\n",
    "    inputs = [\n",
    "        {\"context\": [Document(page_content=text)]} for page_num, text in sorted_texts\n",
    "    ]\n",
    "\n",
    "    # text_summary_chain을 사용하여 일괄 처리로 요약을 생성합니다.\n",
    "    summaries = text_summary_chain.batch(inputs)\n",
    "\n",
    "    # 생성된 요약을 페이지 번호와 함께 딕셔너리에 저장합니다.\n",
    "    for page_num, summary in enumerate(summaries):\n",
    "        text_summary[page_num] = summary\n",
    "\n",
    "    # 요약된 텍스트를 포함한 새로운 GraphState 객체를 반환합니다.\n",
    "    return GraphState(text_summary=text_summary)\n",
    "\n",
    "\n",
    "# create_text_summary 함수를 호출하여 텍스트 요약을 생성합니다.\n",
    "state_out = create_text_summary(state)\n",
    "\n",
    "# 생성된 요약을 기존 state에 업데이트합니다.\n",
    "state.update(state_out)\n",
    "\n",
    "# 요약된 텍스트를 출력합니다.\n",
    "state_out[\"text_summary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image, Table 요약을 위한 데이터 배치 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"page_elements\"][2][\"image_elements\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state[\"text_summary\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_summary_data_batches(state: GraphState):\n",
    "    # 이미지 요약을 위한 데이터 배치를 생성하는 함수\n",
    "    data_batches = []\n",
    "\n",
    "    # 페이지 번호를 오름차순으로 정렬\n",
    "    page_numbers = sorted(list(state[\"page_elements\"].keys()))\n",
    "\n",
    "    for page_num in page_numbers:\n",
    "        # 각 페이지의 요약된 텍스트를 가져옴\n",
    "        text = state[\"text_summary\"][page_num]\n",
    "        # 해당 페이지의 모든 이미지 요소에 대해 반복\n",
    "        for image_element in state[\"page_elements\"][page_num][\"image_elements\"]:\n",
    "            # 이미지 ID를 정수로 변환\n",
    "            image_id = int(image_element[\"id\"])\n",
    "\n",
    "            # 데이터 배치에 이미지 정보, 관련 텍스트, 페이지 번호, ID를 추가\n",
    "            data_batches.append(\n",
    "                {\n",
    "                    \"image\": state[\"images\"][image_id],  # 이미지 파일 경로\n",
    "                    \"text\": text,  # 관련 텍스트 요약\n",
    "                    \"page\": page_num,  # 페이지 번호\n",
    "                    \"id\": image_id,  # 이미지 ID\n",
    "                }\n",
    "            )\n",
    "    # 생성된 데이터 배치를 GraphState 객체에 담아 반환\n",
    "    return GraphState(image_summary_data_batches=data_batches)\n",
    "\n",
    "\n",
    "def create_table_summary_data_batches(state: GraphState):\n",
    "    # 테이블 요약을 위한 데이터 배치를 생성하는 함수\n",
    "    data_batches = []\n",
    "\n",
    "    # 페이지 번호를 오름차순으로 정렬\n",
    "    page_numbers = sorted(list(state[\"page_elements\"].keys()))\n",
    "\n",
    "    for page_num in page_numbers:\n",
    "        # 각 페이지의 요약된 텍스트를 가져옴\n",
    "        text = state[\"text_summary\"][page_num]\n",
    "        # 해당 페이지의 모든 테이블 요소에 대해 반복\n",
    "        for image_element in state[\"page_elements\"][page_num][\"table_elements\"]:\n",
    "            # 테이블 ID를 정수로 변환\n",
    "            image_id = int(image_element[\"id\"])\n",
    "\n",
    "            # 데이터 배치에 테이블 정보, 관련 텍스트, 페이지 번호, ID를 추가\n",
    "            data_batches.append(\n",
    "                {\n",
    "                    \"table\": state[\"tables\"][image_id],  # 테이블 데이터\n",
    "                    \"text\": text,  # 관련 텍스트 요약\n",
    "                    \"page\": page_num,  # 페이지 번호\n",
    "                    \"id\": image_id,  # 테이블 ID\n",
    "                }\n",
    "            )\n",
    "    # 생성된 데이터 배치를 GraphState 객체에 담아 반환\n",
    "    return GraphState(table_summary_data_batches=data_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_out = create_image_summary_data_batches(state)\n",
    "state.update(state_out)\n",
    "state_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_out = create_table_summary_data_batches(state)\n",
    "state.update(state_out)\n",
    "state_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image, Table 요약 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.models import MultiModal\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "def extract_image_summary(data_batches):\n",
    "    # 객체 생성\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,  # 창의성 (0.0 ~ 2.0)\n",
    "        model_name=\"gpt-4o-mini\",  # 모델명\n",
    "    )\n",
    "\n",
    "    system_prompt = \"\"\"You are an expert in extracting useful information from IMAGE.\n",
    "    With a given image, your task is to extract key entities, summarize them, and write useful information that can be used later for retrieval.\"\"\"\n",
    "\n",
    "    image_paths = []\n",
    "    system_prompts = []\n",
    "    user_prompts = []\n",
    "\n",
    "    for data_batch in data_batches:\n",
    "        context = data_batch[\"text\"]\n",
    "        image_path = data_batch[\"image\"]\n",
    "        user_prompt_template = f\"\"\"Here is the context related to the image: {context}\n",
    "        \n",
    "###\n",
    "\n",
    "Output Format:\n",
    "\n",
    "<image>\n",
    "<title>\n",
    "<summary>\n",
    "<entities> \n",
    "</image>\n",
    "\n",
    "\"\"\"\n",
    "        image_paths.append(image_path)\n",
    "        system_prompts.append(system_prompt)\n",
    "        user_prompts.append(user_prompt_template)\n",
    "\n",
    "    # 멀티모달 객체 생성\n",
    "    multimodal_llm = MultiModal(llm)\n",
    "\n",
    "    # 이미지 파일로 부터 질의\n",
    "    answer = multimodal_llm.batch(\n",
    "        image_paths, system_prompts, user_prompts, display_image=False\n",
    "    )\n",
    "    return answer\n",
    "\n",
    "\n",
    "@chain\n",
    "def extract_table_summary(data_batches):\n",
    "    # 객체 생성\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,  # 창의성 (0.0 ~ 2.0)\n",
    "        model_name=\"gpt-4o-mini\",  # 모델명\n",
    "    )\n",
    "\n",
    "    system_prompt = \"You are an expert in extracting useful information from TABLE. With a given image, your task is to extract key entities, summarize them, and write useful information that can be used later for retrieval.\"\n",
    "\n",
    "    image_paths = []\n",
    "    system_prompts = []\n",
    "    user_prompts = []\n",
    "\n",
    "    for data_batch in data_batches:\n",
    "        context = data_batch[\"text\"]\n",
    "        image_path = data_batch[\"table\"]\n",
    "        user_prompt_template = f\"\"\"Here is the context related to the image of table: {context}\n",
    "        \n",
    "###\n",
    "\n",
    "Output Format:\n",
    "\n",
    "<table>\n",
    "<title>\n",
    "<table_summary>\n",
    "<key_entities> \n",
    "<data_insights>\n",
    "</table>\n",
    "\n",
    "\"\"\"\n",
    "        image_paths.append(image_path)\n",
    "        system_prompts.append(system_prompt)\n",
    "        user_prompts.append(user_prompt_template)\n",
    "\n",
    "    # 멀티모달 객체 생성\n",
    "    multimodal_llm = MultiModal(llm)\n",
    "\n",
    "    # 이미지 파일로 부터 질의\n",
    "    answer = multimodal_llm.batch(\n",
    "        image_paths, system_prompts, user_prompts, display_image=False\n",
    "    )\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_summary(state: GraphState):\n",
    "    # 이미지 요약 추출\n",
    "    # extract_image_summary 함수를 호출하여 이미지 요약 생성\n",
    "    image_summaries = extract_image_summary.invoke(\n",
    "        state[\"image_summary_data_batches\"],\n",
    "    )\n",
    "\n",
    "    # 이미지 요약 결과를 저장할 딕셔너리 초기화\n",
    "    image_summary_output = dict()\n",
    "\n",
    "    # 각 데이터 배치와 이미지 요약을 순회하며 처리\n",
    "    for data_batch, image_summary in zip(\n",
    "        state[\"image_summary_data_batches\"], image_summaries\n",
    "    ):\n",
    "        # 데이터 배치의 ID를 키로 사용하여 이미지 요약 저장\n",
    "        image_summary_output[data_batch[\"id\"]] = image_summary\n",
    "\n",
    "    # 이미지 요약 결과를 포함한 새로운 GraphState 객체 반환\n",
    "    return GraphState(image_summary=image_summary_output)\n",
    "\n",
    "\n",
    "# 이미지 요약 생성 함수 실행\n",
    "state_out = create_image_summary(state)\n",
    "\n",
    "# 기존 상태 업데이트\n",
    "state.update(state_out)\n",
    "\n",
    "# 이미지 요약 결과 출력\n",
    "state_out[\"image_summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_summary(state: GraphState):\n",
    "    # 테이블 요약 추출\n",
    "    table_summaries = extract_table_summary.invoke(\n",
    "        state[\"table_summary_data_batches\"],\n",
    "    )\n",
    "\n",
    "    # 테이블 요약 결과를 저장할 딕셔너리 초기화\n",
    "    table_summary_output = dict()\n",
    "\n",
    "    # 각 데이터 배치와 테이블 요약을 순회하며 처리\n",
    "    for data_batch, table_summary in zip(\n",
    "        state[\"table_summary_data_batches\"], table_summaries\n",
    "    ):\n",
    "        # 데이터 배치의 ID를 키로 사용하여 테이블 요약 저장\n",
    "        table_summary_output[data_batch[\"id\"]] = table_summary\n",
    "\n",
    "    # 테이블 요약 결과를 포함한 새로운 GraphState 객체 반환\n",
    "    return GraphState(table_summary=table_summary_output)\n",
    "\n",
    "\n",
    "# 테이블 요약 생성 함수 실행\n",
    "state_out = create_table_summary(state)\n",
    "\n",
    "# 기존 상태 업데이트\n",
    "state.update(state_out)\n",
    "\n",
    "# 테이블 요약 결과 출력\n",
    "state_out[\"table_summary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Markdown 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def table_markdown_extractor(data_batches):\n",
    "    # 객체 생성\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,  # 창의성 (0.0 ~ 2.0)\n",
    "        model_name=\"gpt-4o-mini\",  # 모델명\n",
    "    )\n",
    "\n",
    "    system_prompt = \"You are an expert in converting image of the TABLE into markdown format. Be sure to include all the information in the table. DO NOT narrate, just answer in markdown format.\"\n",
    "\n",
    "    image_paths = []\n",
    "    system_prompts = []\n",
    "    user_prompts = []\n",
    "\n",
    "    for data_batch in data_batches:\n",
    "        image_path = data_batch[\"table\"]\n",
    "        user_prompt_template = f\"\"\"DO NOT wrap your answer in ```markdown``` or any XML tags.\n",
    "        \n",
    "###\n",
    "\n",
    "Output Format:\n",
    "\n",
    "<table_markdown>\n",
    "\n",
    "\"\"\"\n",
    "        image_paths.append(image_path)\n",
    "        system_prompts.append(system_prompt)\n",
    "        user_prompts.append(user_prompt_template)\n",
    "\n",
    "    # 멀티모달 객체 생성\n",
    "    multimodal_llm = MultiModal(llm)\n",
    "\n",
    "    # 이미지 파일로 부터 질의\n",
    "    answer = multimodal_llm.batch(\n",
    "        image_paths, system_prompts, user_prompts, display_image=False\n",
    "    )\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_markdown(state: GraphState):\n",
    "    # table_markdown_extractor를 사용하여 테이블 마크다운 생성\n",
    "    # state[\"table_summary_data_batches\"]에 저장된 테이블 데이터를 사용\n",
    "    table_markdowns = table_markdown_extractor.invoke(\n",
    "        state[\"table_summary_data_batches\"],\n",
    "    )\n",
    "\n",
    "    # 결과를 저장할 딕셔너리 초기화\n",
    "    table_markdown_output = dict()\n",
    "\n",
    "    # 각 데이터 배치와 생성된 테이블 마크다운을 매칭하여 저장\n",
    "    for data_batch, table_summary in zip(\n",
    "        state[\"table_summary_data_batches\"], table_markdowns\n",
    "    ):\n",
    "        # 데이터 배치의 id를 키로 사용하여 테이블 마크다운 저장\n",
    "        table_markdown_output[data_batch[\"id\"]] = table_summary\n",
    "\n",
    "    # 새로운 GraphState 객체 반환, table_markdown 키에 결과 저장\n",
    "    return GraphState(table_markdown=table_markdown_output)\n",
    "\n",
    "\n",
    "# create_table_markdown 함수 실행\n",
    "state_out = create_table_markdown(state)\n",
    "\n",
    "# 기존 state 업데이트\n",
    "state.update(state_out)\n",
    "\n",
    "# 생성된 테이블 마크다운 출력\n",
    "state_out[\"table_markdown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state_out[\"table_markdown\"][12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과물"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"table_summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"table_markdown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"image_summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"text_summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"texts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"text_summary\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
